% CVPR 2022 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
\usepackage[review]{cvpr}      % To produce the REVIEW version
%\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}


% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{*****} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2022}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{\LaTeX\ Author Guidelines for \confName~Proceedings}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}
\maketitle

%%%%%%%%% ABSTRACT
\begin{abstract}
   The ABSTRACT is to be in fully justified italicized text, at the top of the left-hand column, below the author and affiliation information.
   Use the word ``Abstract'' as the title, in 12-point Times, boldface type, centered relative to the column, initially capitalized.
   The abstract is to be in 10-point, single-spaced type.
   Leave two blank lines after the Abstract, then begin the main text.
   Look at previous CVPR abstracts to get a feel for style and length.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
\label{sec:intro}


\section{Related Work}
\label{sec:related}

\textbf{Progress Prediction.} Activity progress, how complete an acitivity is, was first introduced by \cite{becattini2017}. They introduce ProgressNet, an LSTM based network, to predict activity progress on the ucf24 dataset.

\textbf{Phase Prediction.} The current phase an activity is in is often correlated to the progress of the activity, especially in linear activities. 

\textbf{Remaining Surgery Duration.} The remaining time left in a surgery, or any other activity, is directly correlated to the progress of the activity. \cite{twinanda2019} use this to jointly predict surgery progress and remaining surgery duration. 

\section{Method}
\label{sec:method}

\subsection{Definition of Progress}
\label{sec:method:progress}

\subsection{Networks}
We implemented 3 different networks. ProgressNet \cite{becattini2017}, RSDNet \cite{twinanda2019}, and UTE \cite{kukleva2019}.

\subsection{Data}
We use the following datasets: Breakfast (BF) \cite{kuehne2014,kuehne2016}, UCF101-24 \cite{soomro2012}, and cholec80 \cite{nwoye2022}. For BF we have dense trajectories, RSDNet embeddings, and ProgressNet embeddings. For UCF101-24 and Cholec80 we have i3d embeddings, RSDNet embeddings, and ProgressNet embeddings.


\section{Experiments}
\label{sec:experiments}

\begin{table*}
  \centering
  \begin{tabular}{l|ll|ll|ll}
    \toprule
     & \multicolumn{2}{|c|}{breakfast} & \multicolumn{2}{|c|}{cholec80} & \multicolumn{2}{|c}{ucf101-24} \\
     & Normal & Indices & Normal & Indices & Normal & Indices \\
    \midrule
    UTE & 0.114 & 0.019 & 0.050 & 0.024 & 0.103 & 0.034 \\
    RSDNet & 0.067 & 0.058 & 0.024 & 0.024\footnote{Learning to count?}  & 0.195 & 0.097\footnote{Can't train properly on progress due to RSD} \\
    ProgressNet & 0.070 & 0.054 & 0.078 & 0.031 & 0.103 & 0.054\footnote{Implementation not 100\% correct} \\
    \midrule
    Average & \multicolumn{2}{|c|}{0.019} & \multicolumn{2}{|c|}{0.025} & \multicolumn{2}{|c}{0.034} \\
    0.5 & \multicolumn{2}{|c|}{0.083} & \multicolumn{2}{|c|}{0.083} & \multicolumn{2}{|c}{0.083} \\
    Random & \multicolumn{2}{|c|}{0.166} & \multicolumn{2}{|c|}{0.166} & \multicolumn{2}{|c}{0.166} \\

    \bottomrule
  \end{tabular}
  \caption{Normal Data vs. Indices (MSE Loss)}
  \label{tab:overview}
\end{table*}

\begin{table}
   \centering
   \begin{tabular}{@{}lc@{}}
     \toprule
     Data & MSE Loss \\
     \midrule
     BF train/test (Dense Trajectories) & 0.114 \\
     BF train/test (ResNet embeddings) & - \\
     BF train/test (Indices) & 0.019 \\

     BF train/train (Dense Trajectories) & 0.041 \\
     BF train/train (ResNet embeddings) & - \\
     BF train/train (Indices) & 0.017 \\

     \midrule
     Cholec80 (i3d embeddings) & 0.050 \\
     Cholec80 (ResNet embeddings) & - \\
     Cholec80 (Indices) & 0.024 \\ 

     \midrule
     UCF101-24 (i3d embeddings) & 0.103 \\
     UCF101-24 (ResNet embeddings) & - \\
     UCF101-24 (Indices) & 0.034\\

     \bottomrule
   \end{tabular}
   \caption{UTE}
   \label{tab:ute}
 \end{table}

 \begin{table}
   \centering
   \begin{tabular}{@{}lc@{}}
     \toprule
     Data & MSE Loss \\
     \midrule
     BF train/test (Dense Trajectories) & 0.067 \\
     BF train/test (ResNet embeddings) & - \\
     BF train/test (Indices) & 0.058 \\

     \midrule
     Cholec80 (i3d embeddings) & 0.031 \\
     Cholec80 (ResNet embeddings) & 0.024 \\
     Cholec80 (Indices) & 0.024 \\

     Cholec80 sampled (i3d embeddings) & 0.116 \\
     Cholec80 sampled (ResNet embeddings) & 0.05 \\
     Cholec80 sampled (Indices) & 0.070 \\
     
     \midrule
     UCF101-24 (i3d embeddings) & 0.195* \\
     UCF101-24 (RSD embeddings) & -\\
     UCF101-24 (Indices) & 0.097* \\

     \bottomrule
   \end{tabular}
   \caption{RSDNet}
   \label{tab:rsdnet}
 \end{table}

 \begin{table}
  \centering
  \begin{tabular}{@{}lc@{}}
    \toprule
    Data & MSE Loss \\
    \midrule
    BF train/test (Dense Trajectories) & 0.070 \\
    BF train/test (ResNet embeddings) & - \\
    BF train/test (Indices) & 0.054 \\

    \midrule
    Cholec80 (i3d embeddings) & 0.078 \\
    Cholec80 (ResNet embeddings) & - \\
    Cholec80 (Indices) & 0.031 \\

    \midrule
    UCF101-24 (i3d embeddings) & 0.103 \\
    UCF101-24 (RSD embeddings) & -\\
    UCF101-24 (Indices) & 0.054 \\

    \midrule
    UCF101-24 (Frames \& Boxes) & - \\

    \bottomrule
  \end{tabular}
  \caption{ProgressNet}
  \label{tab:progressnet}
\end{table}

Why is this interesting!?
\begin{table}
  \centering
  \begin{tabular}{@{}lc@{}}
    \toprule
    Data & MAE (minutes) \\
    \midrule
    Cholec80 (i3d embeddings) & 12.58 \\
    Cholec80 (RSD embeddings) & 11.06 \\
    Cholec80 (Indices) & 11.21 \\
    \midrule
    Cholec80 sampled (i3d embeddings) & 16.30 \\
    Cholec80 sampled (RSD embeddings) & 12.95 \\
    Cholec80 sampled (Indices) & 18.13 \\
    \bottomrule
  \end{tabular}
  \caption{RSD Predictions}
  \label{tab:rsd_values}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{lllll}
    \toprule
    Dataset & MoF & iou & Mean F1 \\
    \midrule
    Dense Trajectories & 45.1 & 12.7 & 26.5 \\
    Indices & 24.3 & 12.8 & 24.0 \\
    Raw Indices & 25.2 & 12.4 & 24.7 \\
    \midrule

    \bottomrule
  \end{tabular}
  \caption{Unsupervised Action Classes}
  \label{tab:unsup}
\end{table}

\section{Conclusion}
\label{sec:conclusion}

%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
